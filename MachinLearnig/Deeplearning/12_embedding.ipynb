{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39e7868-315a-4c62-9b39-cd29e0a5efca",
   "metadata": {},
   "source": [
    "# 엠베딩\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce60430a-3c59-45e2-b46b-08705daa52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentense = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog',\n",
    "    'Do you think my dog is amazing?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1f97db-885c-41e5-80fc-bb3dd19621b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f5b1f3-0a00-4407-bc2b-f997c2c97b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100,\n",
    "         oov_token = '<oov>')#처리할 수 없는 단어를 표시할 문자 지정\n",
    "tokenizer.fit_on_texts(sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c452eb-6abf-4e92-b599-84b5e5b11a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<oov>': 1,\n",
       " 'my': 2,\n",
       " 'love': 3,\n",
       " 'dog': 4,\n",
       " 'i': 5,\n",
       " 'you': 6,\n",
       " 'cat': 7,\n",
       " 'do': 8,\n",
       " 'think': 9,\n",
       " 'is': 10,\n",
       " 'amazing': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index #많이 나오는 순서대로 인덱스 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b9382e-3b92-4036-83fb-281bf7469305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시퀀스로 변환\n",
    "#원핫 인코딩을 하는 것이다.\n",
    "sentense = tokenizer.texts_to_sequences(sentense)\n",
    "sentense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea03b0e4-78ec-430e-ad10-4bbe55442926",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentense = [\n",
    "    'I really love my dog',\n",
    "    'my dog loves my friend',\n",
    "    'do you think my dog is amazing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21148449-07b8-4a24-991c-2967bc9f105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentense = tokenizer.texts_to_sequences(test_sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9214359d-0149-4f46-9381-8f02736bf4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 설정\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_sentense = pad_sequences(test_sentense, maxlen = 7, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "affdd06b-1b4e-4109-add9-9fd13016728a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sentense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df68aa00-6363-4e9a-8c54-c051f1db9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩을 이용한 임베딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sentense = to_categorical(pad_sentense) #RNN 레이어에 넣을 수 있는 형태로 만들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206aef0d-527a-417f-bbd1-0dd69d108d71",
   "metadata": {},
   "source": [
    "## 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea98b06f-9ac6-404c-970b-13d1b9816eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 임베딩\n",
    "paper = ['많은 것을 바꾸고 싶다면 많은 것을 받아들여라']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea92cec2-54f2-425d-814a-3f6048ce76d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'많은': 1, '것을': 2, '바꾸고': 3, '싶다면': 4, '받아들여라': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d15cf02-158c-494a-8f5f-078101444bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 2, 5]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_paper = tokenizer.texts_to_sequences(paper)\n",
    "idx_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "802cd5e8-d04b-42df-8151-04fe1364e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(idx_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abca1049-df52-4095-b1a7-da15339a4b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 301ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=6, output_dim=3))\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "embedding = model.predict(idx_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35e4f8ab-96c6-40fa-9448-421d98640331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.04804906, -0.02453886, -0.04048765],\n",
       "        [-0.02577537, -0.02168742, -0.03155816],\n",
       "        [-0.02897375,  0.02718853, -0.04962901],\n",
       "        [ 0.02592048, -0.00040679,  0.03144049],\n",
       "        [-0.04804906, -0.02453886, -0.04048765],\n",
       "        [-0.02577537, -0.02168742, -0.03155816],\n",
       "        [-0.01099201, -0.04406706, -0.02745376]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688da4f9-0729-49c4-b84d-219998f31171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
